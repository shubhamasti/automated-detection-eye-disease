{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/anaconda3/envs/tensorflow/lib/python3.8/site-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.21 (you have 1.4.18). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from tensorflow.keras import layers, models\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/fl/ngxwxtkd09l10m23llp7drg80000gn/T/ipykernel_65438/2635536139.py:7: UserWarning: Argument 'alpha_affine' is not valid and will be ignored.\n",
      "  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.5),\n",
      "/var/folders/fl/ngxwxtkd09l10m23llp7drg80000gn/T/ipykernel_65438/2635536139.py:8: UserWarning: Argument 'var_limit' is not valid and will be ignored.\n",
      "  A.GaussianBlur(var_limit=(10.0, 50.0), p=0.2),\n"
     ]
    }
   ],
   "source": [
    "# Define augmentation pipeline\n",
    "augmentation_pipeline = A.Compose([\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "    A.RandomRotate90(p=0.5),\n",
    "    A.RandomBrightnessContrast(p=0.2),\n",
    "    A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.5),\n",
    "    A.GaussianBlur(var_limit=(10.0, 50.0), p=0.2),\n",
    "    A.RandomGamma(gamma_limit=(80, 120), p=0.2),\n",
    "    A.RandomResizedCrop(height=256, width=256, scale=(0.8, 1.0), p=0.3)\n",
    "])\n",
    "\n",
    "# Augment images and masks\n",
    "def augment_image_and_mask(image, mask):\n",
    "    # pass image and mask to augmentation pipeline so that the same transformation is applied to both\n",
    "    augmented = augmentation_pipeline(image=image, mask=mask)\n",
    "    return augmented['image'], augmented['mask']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to load data from train and test directories\n",
    "def load_dataset_refuge(train_dir, val_dir, test_dir, image_size):\n",
    "    all_images = []\n",
    "    all_masks = []\n",
    "    \n",
    "    train_img_dir = os.path.join(train_dir, 'Images')\n",
    "    train_mask_dir = os.path.join(train_dir, 'gts')\n",
    "    \n",
    "    val_img_dir = os.path.join(val_dir, 'Images')\n",
    "    val_mask_dir = os.path.join(val_dir, 'gts')\n",
    "    \n",
    "    test_img_dir = os.path.join(test_dir, 'Images')\n",
    "    test_mask_dir = os.path.join(test_dir, 'gts')\n",
    "    \n",
    "    for img_path in tqdm(os.listdir(train_img_dir)):\n",
    "        basename = img_path.split('.')[0]\n",
    "        img_path = os.path.join(train_img_dir, img_path)\n",
    "        mask_path = os.path.join(train_mask_dir, basename + '.bmp')\n",
    "        \n",
    "        img = load_img(img_path, target_size=image_size)\n",
    "        mask = load_img(mask_path, target_size=image_size, color_mode=\"grayscale\")\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        mask_array = img_to_array(mask) / 255.0\n",
    "        \n",
    "        img_array, mask_array = augment_image_and_mask(img_array, mask_array)\n",
    "    \n",
    "        all_images.append(img_array)\n",
    "        all_masks.append(mask_array)\n",
    "\n",
    "    for img_path in tqdm(os.listdir(val_img_dir)):\n",
    "        basename = img_path.split('.')[0]\n",
    "        img_path = os.path.join(val_img_dir, img_path)\n",
    "        mask_path = os.path.join(val_mask_dir, basename + '.bmp')\n",
    "        \n",
    "        img = load_img(img_path, target_size=image_size)\n",
    "        mask = load_img(mask_path, target_size=image_size, color_mode=\"grayscale\")\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        mask_array = img_to_array(mask) / 255.0\n",
    "        \n",
    "        img_array, mask_array = augment_image_and_mask(img_array, mask_array)\n",
    "        \n",
    "        all_images.append(img_array)\n",
    "        all_masks.append(mask_array)\n",
    "    \n",
    "    for img_path in tqdm(os.listdir(test_img_dir)):\n",
    "        basename = img_path.split('.')[0]\n",
    "        img_path = os.path.join(test_img_dir, img_path)\n",
    "        mask_path = os.path.join(test_mask_dir, basename + '.bmp')\n",
    "        \n",
    "        img = load_img(img_path, target_size=image_size)\n",
    "        mask = load_img(mask_path, target_size=image_size, color_mode=\"grayscale\")\n",
    "        img_array = img_to_array(img) / 255.0\n",
    "        mask_array = img_to_array(mask) / 255.0\n",
    "        \n",
    "        img_array, mask_array = augment_image_and_mask(img_array, mask_array)\n",
    "    \n",
    "        all_images.append(img_array)\n",
    "        all_masks.append(mask_array)\n",
    "        \n",
    "    return np.array(all_images), np.array(all_masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [00:09<00:00, 40.50it/s]\n",
      "100%|██████████| 400/400 [00:05<00:00, 74.77it/s]\n",
      "100%|██████████| 400/400 [00:05<00:00, 74.38it/s]\n"
     ]
    }
   ],
   "source": [
    "# Directories for images and masks\n",
    "train_dir = 'path/to/REFUGE/train'\n",
    "val_dir = 'path/to/REFUGE/val'\n",
    "test_dir = 'path/to/REFUGE/test'\n",
    "image_size = (256, 256)\n",
    "\n",
    "all_images, all_masks = load_dataset_refuge(train_dir, val_dir, test_dir, image_size)\n",
    "\n",
    "# Split into training and test sets (80% train, 20% test)\n",
    "train_images, test_images, train_masks, test_masks = train_test_split(\n",
    "    all_images, all_masks, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# split train set into training and validation sets (90% train, 10% validation)\n",
    "val_images, test_images, val_masks, test_masks = train_test_split(\n",
    "    test_images, test_masks, test_size=0.5, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((840, 256, 256, 3), (180, 256, 256, 3), (180, 256, 256, 3))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape, val_images.shape, test_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((840, 256, 256, 1), (180, 256, 256, 1), (180, 256, 256, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_masks.shape, val_masks.shape, test_masks.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unet_model(input_size=(256, 256, 3)):\n",
    "    inputs = layers.Input(input_size)\n",
    "    \n",
    "    # Encoder\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(inputs)\n",
    "    conv1 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv1)\n",
    "    pool1 = layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    \n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(pool1)\n",
    "    conv2 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv2)\n",
    "    pool2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    \n",
    "    # Bottleneck\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(pool2)\n",
    "    conv3 = layers.Conv2D(256, 3, activation='relu', padding='same')(conv3)\n",
    "    \n",
    "    # Decoder\n",
    "    up1 = layers.UpSampling2D(size=(2, 2))(conv3)\n",
    "    up1 = layers.concatenate([up1, conv2], axis=-1)\n",
    "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(up1)\n",
    "    conv4 = layers.Conv2D(128, 3, activation='relu', padding='same')(conv4)\n",
    "    \n",
    "    up2 = layers.UpSampling2D(size=(2, 2))(conv4)\n",
    "    up2 = layers.concatenate([up2, conv1], axis=-1)\n",
    "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(up2)\n",
    "    conv5 = layers.Conv2D(64, 3, activation='relu', padding='same')(conv5)\n",
    "    \n",
    "    outputs = layers.Conv2D(1, 1, activation='sigmoid')(conv5)  # Sigmoid for binary classification\n",
    "    \n",
    "    model = models.Model(inputs=[inputs], outputs=[outputs])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 11:33:06.817949: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-06 11:33:06.818582: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = unet_model(input_size=(256, 256, 3))\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy', \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 256, 256, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 256, 256, 64  1792        ['input_1[0][0]']                \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d[0][0]']                 \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 128, 128, 64  0           ['conv2d_1[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 128, 128, 12  73856       ['max_pooling2d[0][0]']          \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_2[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 128)  0          ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 64, 64, 256)  295168      ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 64, 64, 256)  590080      ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " up_sampling2d (UpSampling2D)   (None, 128, 128, 25  0           ['conv2d_5[0][0]']               \n",
      "                                6)                                                                \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 128, 128, 38  0           ['up_sampling2d[0][0]',          \n",
      "                                4)                                'conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 128, 128, 12  442496      ['concatenate[0][0]']            \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)              (None, 128, 128, 12  147584      ['conv2d_6[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " up_sampling2d_1 (UpSampling2D)  (None, 256, 256, 12  0          ['conv2d_7[0][0]']               \n",
      "                                8)                                                                \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 256, 256, 19  0           ['up_sampling2d_1[0][0]',        \n",
      "                                2)                                'conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)              (None, 256, 256, 64  110656      ['concatenate_1[0][0]']          \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)              (None, 256, 256, 64  36928       ['conv2d_8[0][0]']               \n",
      "                                )                                                                 \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)             (None, 256, 256, 1)  65          ['conv2d_9[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 1,883,137\n",
      "Trainable params: 1,883,137\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 11:33:09.397691: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-12-06 11:33:09.747182: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - ETA: 0s - loss: 0.1108 - accuracy: 0.9785"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-06 11:34:25.299461: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52/52 [==============================] - 81s 2s/step - loss: 0.1108 - accuracy: 0.9785 - val_loss: 0.0351 - val_accuracy: 0.9831\n",
      "Epoch 2/50\n",
      "52/52 [==============================] - 69s 1s/step - loss: 0.0327 - accuracy: 0.9827 - val_loss: 0.0266 - val_accuracy: 0.9831\n",
      "Epoch 3/50\n",
      "52/52 [==============================] - 67s 1s/step - loss: 0.0260 - accuracy: 0.9828 - val_loss: 0.0192 - val_accuracy: 0.9831\n",
      "Epoch 4/50\n",
      "52/52 [==============================] - 71s 1s/step - loss: 0.0211 - accuracy: 0.9845 - val_loss: 0.0186 - val_accuracy: 0.9857\n",
      "Epoch 5/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0174 - accuracy: 0.9858 - val_loss: 0.0152 - val_accuracy: 0.9867\n",
      "Epoch 6/50\n",
      "52/52 [==============================] - 68s 1s/step - loss: 0.0174 - accuracy: 0.9857 - val_loss: 0.0164 - val_accuracy: 0.9864\n",
      "Epoch 7/50\n",
      "52/52 [==============================] - 69s 1s/step - loss: 0.0157 - accuracy: 0.9862 - val_loss: 0.0155 - val_accuracy: 0.9867\n",
      "Epoch 8/50\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.0149 - accuracy: 0.9865 - val_loss: 0.0142 - val_accuracy: 0.9868\n",
      "Epoch 9/50\n",
      "52/52 [==============================] - 68s 1s/step - loss: 0.0147 - accuracy: 0.9865 - val_loss: 0.0140 - val_accuracy: 0.9870\n",
      "Epoch 10/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0147 - accuracy: 0.9866 - val_loss: 0.0135 - val_accuracy: 0.9871\n",
      "Epoch 11/50\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.0140 - accuracy: 0.9868 - val_loss: 0.0139 - val_accuracy: 0.9872\n",
      "Epoch 12/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0139 - accuracy: 0.9867 - val_loss: 0.0140 - val_accuracy: 0.9872\n",
      "Epoch 13/50\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.0148 - accuracy: 0.9866 - val_loss: 0.0132 - val_accuracy: 0.9873\n",
      "Epoch 14/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0128 - accuracy: 0.9870 - val_loss: 0.0129 - val_accuracy: 0.9874\n",
      "Epoch 15/50\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.0126 - accuracy: 0.9869 - val_loss: 0.0130 - val_accuracy: 0.9873\n",
      "Epoch 16/50\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.0129 - accuracy: 0.9870 - val_loss: 0.0127 - val_accuracy: 0.9873\n",
      "Epoch 17/50\n",
      "52/52 [==============================] - 61s 1s/step - loss: 0.0128 - accuracy: 0.9870 - val_loss: 0.0130 - val_accuracy: 0.9873\n",
      "Epoch 18/50\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.0124 - accuracy: 0.9870 - val_loss: 0.0125 - val_accuracy: 0.9874\n",
      "Epoch 19/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0122 - accuracy: 0.9871 - val_loss: 0.0123 - val_accuracy: 0.9874\n",
      "Epoch 20/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0121 - accuracy: 0.9871 - val_loss: 0.0124 - val_accuracy: 0.9874\n",
      "Epoch 21/50\n",
      "52/52 [==============================] - 66s 1s/step - loss: 0.0121 - accuracy: 0.9870 - val_loss: 0.0124 - val_accuracy: 0.9874\n",
      "Epoch 22/50\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.0126 - accuracy: 0.9869 - val_loss: 0.0127 - val_accuracy: 0.9873\n",
      "Epoch 23/50\n",
      "52/52 [==============================] - 67s 1s/step - loss: 0.0124 - accuracy: 0.9869 - val_loss: 0.0125 - val_accuracy: 0.9874\n",
      "Epoch 24/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0124 - accuracy: 0.9870 - val_loss: 0.0125 - val_accuracy: 0.9874\n",
      "Epoch 25/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0124 - accuracy: 0.9871 - val_loss: 0.0128 - val_accuracy: 0.9874\n",
      "Epoch 26/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0121 - accuracy: 0.9870 - val_loss: 0.0126 - val_accuracy: 0.9874\n",
      "Epoch 27/50\n",
      "52/52 [==============================] - 62s 1s/step - loss: 0.0117 - accuracy: 0.9872 - val_loss: 0.0119 - val_accuracy: 0.9874\n",
      "Epoch 28/50\n",
      "52/52 [==============================] - 61s 1s/step - loss: 0.0117 - accuracy: 0.9870 - val_loss: 0.0121 - val_accuracy: 0.9874\n",
      "Epoch 29/50\n",
      "52/52 [==============================] - 61s 1s/step - loss: 0.0117 - accuracy: 0.9871 - val_loss: 0.0123 - val_accuracy: 0.9874\n",
      "Epoch 30/50\n",
      "52/52 [==============================] - 60s 1s/step - loss: 0.0118 - accuracy: 0.9871 - val_loss: 0.0127 - val_accuracy: 0.9874\n",
      "Epoch 31/50\n",
      "52/52 [==============================] - 61s 1s/step - loss: 0.0118 - accuracy: 0.9870 - val_loss: 0.0117 - val_accuracy: 0.9875\n",
      "Epoch 32/50\n",
      "52/52 [==============================] - 61s 1s/step - loss: 0.0115 - accuracy: 0.9872 - val_loss: 0.0119 - val_accuracy: 0.9875\n",
      "Epoch 33/50\n",
      "52/52 [==============================] - 59s 1s/step - loss: 0.0116 - accuracy: 0.9871 - val_loss: 0.0121 - val_accuracy: 0.9874\n",
      "Epoch 34/50\n",
      "52/52 [==============================] - 60s 1s/step - loss: 0.0120 - accuracy: 0.9870 - val_loss: 0.0132 - val_accuracy: 0.9872\n",
      "Epoch 35/50\n",
      "52/52 [==============================] - 60s 1s/step - loss: 0.0118 - accuracy: 0.9871 - val_loss: 0.0123 - val_accuracy: 0.9874\n",
      "Epoch 36/50\n",
      "52/52 [==============================] - 61s 1s/step - loss: 0.0117 - accuracy: 0.9870 - val_loss: 0.0121 - val_accuracy: 0.9874\n",
      "Epoch 37/50\n",
      "52/52 [==============================] - 61s 1s/step - loss: 0.0114 - accuracy: 0.9871 - val_loss: 0.0117 - val_accuracy: 0.9875\n",
      "Epoch 38/50\n",
      "52/52 [==============================] - 60s 1s/step - loss: 0.0112 - accuracy: 0.9872 - val_loss: 0.0118 - val_accuracy: 0.9875\n",
      "Epoch 39/50\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.0114 - accuracy: 0.9871 - val_loss: 0.0122 - val_accuracy: 0.9874\n",
      "Epoch 40/50\n",
      "52/52 [==============================] - 73s 1s/step - loss: 0.0112 - accuracy: 0.9872 - val_loss: 0.0120 - val_accuracy: 0.9874\n",
      "Epoch 41/50\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.0112 - accuracy: 0.9872 - val_loss: 0.0117 - val_accuracy: 0.9875\n",
      "Epoch 42/50\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.0116 - accuracy: 0.9870 - val_loss: 0.0122 - val_accuracy: 0.9874\n",
      "Epoch 43/50\n",
      "52/52 [==============================] - 64s 1s/step - loss: 0.0118 - accuracy: 0.9870 - val_loss: 0.0122 - val_accuracy: 0.9874\n",
      "Epoch 44/50\n",
      "52/52 [==============================] - 63s 1s/step - loss: 0.0115 - accuracy: 0.9871 - val_loss: 0.0121 - val_accuracy: 0.9874\n",
      "Epoch 45/50\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.0120 - accuracy: 0.9871 - val_loss: 0.0117 - val_accuracy: 0.9874\n",
      "Epoch 46/50\n",
      "52/52 [==============================] - 67s 1s/step - loss: 0.0114 - accuracy: 0.9871 - val_loss: 0.0117 - val_accuracy: 0.9875\n",
      "Epoch 47/50\n",
      "52/52 [==============================] - 65s 1s/step - loss: 0.0115 - accuracy: 0.9870 - val_loss: 0.0130 - val_accuracy: 0.9870\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss', patience=10, restore_best_weights=True\n",
    ")\n",
    "\n",
    "history = model.fit(train_images, train_masks, epochs=50,\n",
    "                    batch_size=16, verbose=1, steps_per_epoch=len(train_images) // 16,\n",
    "                    validation_data=(val_images, val_masks),\n",
    "                    callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 6s 871ms/step - loss: 0.0117 - accuracy: 0.9875\n",
      "Validation Loss: 0.01\n",
      "Validation Accuracy: 98.75%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(val_images, val_masks)\n",
    "print(\"Validation Loss: %.2f\" % scores[0])\n",
    "print(\"Validation Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 5s 793ms/step - loss: 0.0131 - accuracy: 0.9870\n",
      "Test Loss: 0.01\n",
      "Test Accuracy: 98.70%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(test_images, test_masks)\n",
    "print(\"Test Loss: %.2f\" % scores[0])\n",
    "print(\"Test Accuracy: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_json = model.to_json()\n",
    "with open('../models_segmentation/ODOC.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Saving the model and weights\n",
    "model.save_weights('../models_segmentation/ODOC.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
