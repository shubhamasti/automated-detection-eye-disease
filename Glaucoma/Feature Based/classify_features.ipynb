{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle, resample\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import load_img, img_to_array, to_categorical\n",
    "from keras.models import model_from_json, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "IMAGE_SIZE = (256, 256)  # Example size, adjust to your models\n",
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 11:38:50.985952: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-12-09 11:38:50.986083: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M2 Pro\n",
      "\n",
      "systemMemory: 16.00 GB\n",
      "maxCacheSize: 5.33 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# OD and OD\n",
    "with open('../models_segmentation/ODOC.json', 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights('../models_segmentation/ODOC.weights.h5')\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to preprocess images\n",
    "def preprocess_image(image_path):\n",
    "    img = load_img(image_path, target_size=IMAGE_SIZE)\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def generate_feature_maps(image_path):\n",
    "    # Apply the specific preprocessing method for each model\n",
    "    img = preprocess_image(image_path)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    \n",
    "    mask = model.predict(img, verbose=False)  # Predict mask    \n",
    "    mask_discrete = np.zeros_like(mask)  # Initialize with zeros\n",
    "    mask_discrete[(mask >= 0.25) & (mask < 0.75)] = 0.5  # Set to 0.5 where within range\n",
    "    mask_discrete[mask >= 0.75] = 1\n",
    "    # Combine masks into a single feature map\n",
    "    combined = np.transpose(mask_discrete, (1, 2, 0, 3))\n",
    "    combined = np.squeeze(combined)\n",
    "    \n",
    "    return combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load images and labels - ORIGA\n",
    "def load_data(img_path, csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    X, y = [], []\n",
    "    \n",
    "    for row in tqdm(df.itertuples(), total=len(df)):\n",
    "        img = generate_feature_maps(os.path.join(img_path, row[2])) \n",
    "        X.append(img)\n",
    "        y.append(row[5])\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "def load_balanced_data(img_path, csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    X, y = [], []\n",
    "\n",
    "    # Define target sample sizes for each label\n",
    "    target_sizes = {\n",
    "        0: 200,\n",
    "        1: 200\n",
    "    }\n",
    "\n",
    "    # Initialize a list to hold the sliced DataFrames\n",
    "    sliced_dfs = []\n",
    "\n",
    "    # Slice the DataFrame for each label\n",
    "    for label, size in target_sizes.items():\n",
    "        class_df = df[df['Glaucoma'] == label]\n",
    "        if len(class_df) >= size:\n",
    "            # Undersample if the class size is greater than or equal to the target size\n",
    "            sliced_df = class_df.sample(size, random_state=42)\n",
    "        else:\n",
    "            # Oversample if the class size is smaller than the target size\n",
    "            sliced_df = resample(class_df, replace=True, n_samples=size, random_state=42)\n",
    "        sliced_dfs.append(sliced_df)\n",
    "\n",
    "    # Combine all sliced DataFrames\n",
    "    final_df = pd.concat(sliced_dfs)\n",
    "\n",
    "    # Shuffle the final dataset\n",
    "    final_df = shuffle(final_df, random_state=42)\n",
    "    \n",
    "    for row in tqdm(final_df.itertuples(), total=len(final_df)):\n",
    "        img = generate_feature_maps(os.path.join(img_path, row[2]))\n",
    "        X.append(img)\n",
    "        y.append(row[5])\n",
    "        \n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Function to load images and labels - REFUGE\n",
    "def load_dataset_refuge(train_dir, val_dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    train_img_dir = os.path.join(train_dir, 'Images')\n",
    "    df_train = pd.read_csv(os.path.join(train_dir, 'output.csv'))\n",
    "    \n",
    "    val_img_dir = os.path.join(val_dir, 'Images')\n",
    "    df_val = pd.read_csv(os.path.join(val_dir, 'output.csv'))\n",
    "    \n",
    "    # iterate through the train df\n",
    "    for row in tqdm(df_train.itertuples(), total=len(df_train)):\n",
    "        img_path = os.path.join(train_img_dir, row[1])\n",
    "        img = generate_feature_maps(img_path)\n",
    "        X.append(img)\n",
    "        y.append(row[6])\n",
    "    \n",
    "    # iterate through the val df\n",
    "    for row in tqdm(df_val.itertuples(), total=len(df_val)):\n",
    "        img_path = os.path.join(val_img_dir, row[1])\n",
    "        img = generate_feature_maps(img_path)\n",
    "        X.append(img)\n",
    "        y.append(row[2])\n",
    "\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Function to load images and labels - ORIGA\n",
    "def load_data_origa(img_path, csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    X, y = [], []\n",
    "    \n",
    "    for row in tqdm(df.itertuples(), total=len(df)):\n",
    "        img = generate_feature_maps(os.path.join(img_path, row[2])) \n",
    "        X.append(img)\n",
    "        y.append(row[5])\n",
    "        \n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/650 [00:00<?, ?it/s]2024-12-09 11:39:17.172029: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-12-09 11:39:17.250741: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "100%|██████████| 650/650 [00:42<00:00, 15.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: (455, 256, 256), (455, 2)\n",
      "Validation set: (98, 256, 256), (98, 2)\n",
      "Test set: (97, 256, 256), (97, 2)\n"
     ]
    }
   ],
   "source": [
    "csv_path = 'path/to/ORIGA/OrigaList.csv'\n",
    "img_path = 'path/to/ORIGA/Images'\n",
    "\n",
    "X, y = load_data_origa(img_path, csv_path)\n",
    "\n",
    "# train test validation split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, random_state=42)\n",
    "\n",
    "# convert labels to one-hot encoding\n",
    "y_train = to_categorical(y_train, num_classes=NUM_CLASSES)\n",
    "y_val = to_categorical(y_val, num_classes=NUM_CLASSES)\n",
    "y_test = to_categorical(y_test, num_classes=NUM_CLASSES)\n",
    "\n",
    "print(f\"Train set: {X_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation set: {X_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test set: {X_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 254, 254, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 127, 127, 32)     0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 125, 125, 64)      18496     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 62, 62, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 60, 60, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 30, 30, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 28, 28, 256)       295168    \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 256)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              263168    \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 1024)              0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               131328    \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 32)                0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dropout_6 (Dropout)         (None, 16)                0         \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 2)                 34        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,350,930\n",
      "Trainable params: 1,350,930\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "classification_model = tf.keras.Sequential([\n",
    "    # First Conv2D layer\n",
    "    tf.keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),  # Optional pooling layer\n",
    "\n",
    "    # Second Conv2D layer\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),  # Optional pooling layer\n",
    "\n",
    "    # Third Conv2D layer\n",
    "    tf.keras.layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    \n",
    "    tf.keras.layers.Conv2D(256, (3, 3), activation='relu'),\n",
    "\n",
    "    # Global pooling to reduce to 2D tensor\n",
    "    tf.keras.layers.GlobalAveragePooling2D(),\n",
    "\n",
    "    # Fully connected layers\n",
    "    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.3),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')  # Output layer with 5 classes\n",
    "])\n",
    "\n",
    "classification_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=20,          # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restore weights from the epoch with the best validation loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 11:40:32.726778: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - ETA: 0s - loss: 0.6584 - accuracy: 0.6945"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-12-09 11:40:37.902329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15/15 [==============================] - 7s 341ms/step - loss: 0.6584 - accuracy: 0.6945 - val_loss: 0.6439 - val_accuracy: 0.7347\n",
      "Epoch 2/200\n",
      "15/15 [==============================] - 1s 95ms/step - loss: 0.6023 - accuracy: 0.7407 - val_loss: 0.5982 - val_accuracy: 0.7347\n",
      "Epoch 3/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5894 - accuracy: 0.7407 - val_loss: 0.5917 - val_accuracy: 0.7347\n",
      "Epoch 4/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5852 - accuracy: 0.7407 - val_loss: 0.6032 - val_accuracy: 0.7347\n",
      "Epoch 5/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5943 - accuracy: 0.7407 - val_loss: 0.5869 - val_accuracy: 0.7347\n",
      "Epoch 6/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5897 - accuracy: 0.7407 - val_loss: 0.5956 - val_accuracy: 0.7347\n",
      "Epoch 7/200\n",
      "15/15 [==============================] - 1s 91ms/step - loss: 0.5825 - accuracy: 0.7407 - val_loss: 0.5937 - val_accuracy: 0.7347\n",
      "Epoch 8/200\n",
      "15/15 [==============================] - 1s 94ms/step - loss: 0.5751 - accuracy: 0.7407 - val_loss: 0.5799 - val_accuracy: 0.7347\n",
      "Epoch 9/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5874 - accuracy: 0.7407 - val_loss: 0.5870 - val_accuracy: 0.7347\n",
      "Epoch 10/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.5806 - accuracy: 0.7407 - val_loss: 0.5833 - val_accuracy: 0.7347\n",
      "Epoch 11/200\n",
      "15/15 [==============================] - 1s 91ms/step - loss: 0.5802 - accuracy: 0.7407 - val_loss: 0.5814 - val_accuracy: 0.7347\n",
      "Epoch 12/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5823 - accuracy: 0.7407 - val_loss: 0.5800 - val_accuracy: 0.7347\n",
      "Epoch 13/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5746 - accuracy: 0.7407 - val_loss: 0.5813 - val_accuracy: 0.7347\n",
      "Epoch 14/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5852 - accuracy: 0.7407 - val_loss: 0.5801 - val_accuracy: 0.7347\n",
      "Epoch 15/200\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 0.5806 - accuracy: 0.7407 - val_loss: 0.5848 - val_accuracy: 0.7347\n",
      "Epoch 16/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5846 - accuracy: 0.7407 - val_loss: 0.5879 - val_accuracy: 0.7347\n",
      "Epoch 17/200\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.5712 - accuracy: 0.7407 - val_loss: 0.5796 - val_accuracy: 0.7347\n",
      "Epoch 18/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.5832 - accuracy: 0.7407 - val_loss: 0.5797 - val_accuracy: 0.7347\n",
      "Epoch 19/200\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 0.5781 - accuracy: 0.7407 - val_loss: 0.5832 - val_accuracy: 0.7347\n",
      "Epoch 20/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5739 - accuracy: 0.7407 - val_loss: 0.5810 - val_accuracy: 0.7347\n",
      "Epoch 21/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5795 - accuracy: 0.7407 - val_loss: 0.5802 - val_accuracy: 0.7347\n",
      "Epoch 22/200\n",
      "15/15 [==============================] - 1s 87ms/step - loss: 0.5739 - accuracy: 0.7407 - val_loss: 0.5830 - val_accuracy: 0.7347\n",
      "Epoch 23/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5783 - accuracy: 0.7407 - val_loss: 0.5826 - val_accuracy: 0.7347\n",
      "Epoch 24/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5726 - accuracy: 0.7407 - val_loss: 0.5811 - val_accuracy: 0.7347\n",
      "Epoch 25/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5815 - accuracy: 0.7407 - val_loss: 0.5809 - val_accuracy: 0.7347\n",
      "Epoch 26/200\n",
      "15/15 [==============================] - 1s 87ms/step - loss: 0.5837 - accuracy: 0.7407 - val_loss: 0.5802 - val_accuracy: 0.7347\n",
      "Epoch 27/200\n",
      "15/15 [==============================] - 1s 87ms/step - loss: 0.5814 - accuracy: 0.7407 - val_loss: 0.5890 - val_accuracy: 0.7347\n",
      "Epoch 28/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5699 - accuracy: 0.7407 - val_loss: 0.5795 - val_accuracy: 0.7347\n",
      "Epoch 29/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5838 - accuracy: 0.7407 - val_loss: 0.5804 - val_accuracy: 0.7347\n",
      "Epoch 30/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5762 - accuracy: 0.7407 - val_loss: 0.5801 - val_accuracy: 0.7347\n",
      "Epoch 31/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.5732 - accuracy: 0.7407 - val_loss: 0.5774 - val_accuracy: 0.7347\n",
      "Epoch 32/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5724 - accuracy: 0.7407 - val_loss: 0.5772 - val_accuracy: 0.7347\n",
      "Epoch 33/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5689 - accuracy: 0.7407 - val_loss: 0.5832 - val_accuracy: 0.7347\n",
      "Epoch 34/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5708 - accuracy: 0.7407 - val_loss: 0.5734 - val_accuracy: 0.7347\n",
      "Epoch 35/200\n",
      "15/15 [==============================] - 1s 87ms/step - loss: 0.5744 - accuracy: 0.7407 - val_loss: 0.5736 - val_accuracy: 0.7347\n",
      "Epoch 36/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5684 - accuracy: 0.7407 - val_loss: 0.5696 - val_accuracy: 0.7347\n",
      "Epoch 37/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5644 - accuracy: 0.7407 - val_loss: 0.5744 - val_accuracy: 0.7347\n",
      "Epoch 38/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5756 - accuracy: 0.7407 - val_loss: 0.5782 - val_accuracy: 0.7347\n",
      "Epoch 39/200\n",
      "15/15 [==============================] - 1s 91ms/step - loss: 0.5715 - accuracy: 0.7407 - val_loss: 0.5792 - val_accuracy: 0.7347\n",
      "Epoch 40/200\n",
      "15/15 [==============================] - 1s 91ms/step - loss: 0.5691 - accuracy: 0.7407 - val_loss: 0.5707 - val_accuracy: 0.7347\n",
      "Epoch 41/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.5537 - accuracy: 0.7407 - val_loss: 0.5629 - val_accuracy: 0.7347\n",
      "Epoch 42/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5437 - accuracy: 0.7407 - val_loss: 0.5783 - val_accuracy: 0.7347\n",
      "Epoch 43/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5714 - accuracy: 0.7429 - val_loss: 0.5756 - val_accuracy: 0.7347\n",
      "Epoch 44/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5798 - accuracy: 0.7407 - val_loss: 0.5811 - val_accuracy: 0.7347\n",
      "Epoch 45/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5545 - accuracy: 0.7407 - val_loss: 0.5703 - val_accuracy: 0.7347\n",
      "Epoch 46/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5550 - accuracy: 0.7451 - val_loss: 0.5610 - val_accuracy: 0.7347\n",
      "Epoch 47/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5469 - accuracy: 0.7407 - val_loss: 0.5569 - val_accuracy: 0.7347\n",
      "Epoch 48/200\n",
      "15/15 [==============================] - 1s 93ms/step - loss: 0.5467 - accuracy: 0.7319 - val_loss: 0.5537 - val_accuracy: 0.7347\n",
      "Epoch 49/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.5465 - accuracy: 0.7407 - val_loss: 0.5654 - val_accuracy: 0.7347\n",
      "Epoch 50/200\n",
      "15/15 [==============================] - 1s 96ms/step - loss: 0.5407 - accuracy: 0.7385 - val_loss: 0.5583 - val_accuracy: 0.7347\n",
      "Epoch 51/200\n",
      "15/15 [==============================] - 1s 95ms/step - loss: 0.5375 - accuracy: 0.7429 - val_loss: 0.5584 - val_accuracy: 0.7347\n",
      "Epoch 52/200\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.5269 - accuracy: 0.7407 - val_loss: 0.5427 - val_accuracy: 0.7449\n",
      "Epoch 53/200\n",
      "15/15 [==============================] - 1s 87ms/step - loss: 0.5077 - accuracy: 0.7516 - val_loss: 0.5885 - val_accuracy: 0.6531\n",
      "Epoch 54/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5508 - accuracy: 0.7055 - val_loss: 0.6087 - val_accuracy: 0.7449\n",
      "Epoch 55/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5451 - accuracy: 0.7495 - val_loss: 0.5483 - val_accuracy: 0.7449\n",
      "Epoch 56/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5194 - accuracy: 0.7495 - val_loss: 0.5441 - val_accuracy: 0.7449\n",
      "Epoch 57/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.5123 - accuracy: 0.7429 - val_loss: 0.5388 - val_accuracy: 0.7449\n",
      "Epoch 58/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.4854 - accuracy: 0.7714 - val_loss: 0.5550 - val_accuracy: 0.7551\n",
      "Epoch 59/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.5268 - accuracy: 0.7714 - val_loss: 0.5610 - val_accuracy: 0.7245\n",
      "Epoch 60/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.5089 - accuracy: 0.7868 - val_loss: 0.5436 - val_accuracy: 0.7347\n",
      "Epoch 61/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.4592 - accuracy: 0.8000 - val_loss: 0.5359 - val_accuracy: 0.7041\n",
      "Epoch 62/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.4429 - accuracy: 0.8176 - val_loss: 0.5522 - val_accuracy: 0.7041\n",
      "Epoch 63/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.4637 - accuracy: 0.8110 - val_loss: 0.8257 - val_accuracy: 0.4898\n",
      "Epoch 64/200\n",
      "15/15 [==============================] - 1s 87ms/step - loss: 0.4928 - accuracy: 0.7714 - val_loss: 0.5615 - val_accuracy: 0.6837\n",
      "Epoch 65/200\n",
      "15/15 [==============================] - 1s 92ms/step - loss: 0.4496 - accuracy: 0.8352 - val_loss: 0.5546 - val_accuracy: 0.7041\n",
      "Epoch 66/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.4158 - accuracy: 0.8220 - val_loss: 0.5384 - val_accuracy: 0.7449\n",
      "Epoch 67/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.3948 - accuracy: 0.8484 - val_loss: 0.5564 - val_accuracy: 0.7347\n",
      "Epoch 68/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.3819 - accuracy: 0.8505 - val_loss: 0.5770 - val_accuracy: 0.7245\n",
      "Epoch 69/200\n",
      "15/15 [==============================] - 1s 99ms/step - loss: 0.3302 - accuracy: 0.8725 - val_loss: 0.7261 - val_accuracy: 0.7347\n",
      "Epoch 70/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.4481 - accuracy: 0.8088 - val_loss: 0.6237 - val_accuracy: 0.6327\n",
      "Epoch 71/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.3818 - accuracy: 0.8242 - val_loss: 0.5863 - val_accuracy: 0.7347\n",
      "Epoch 72/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.3619 - accuracy: 0.8418 - val_loss: 0.5635 - val_accuracy: 0.7551\n",
      "Epoch 73/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.3700 - accuracy: 0.8725 - val_loss: 0.5863 - val_accuracy: 0.7347\n",
      "Epoch 74/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.3966 - accuracy: 0.8374 - val_loss: 0.5404 - val_accuracy: 0.7755\n",
      "Epoch 75/200\n",
      "15/15 [==============================] - 1s 90ms/step - loss: 0.3267 - accuracy: 0.8967 - val_loss: 0.5873 - val_accuracy: 0.7245\n",
      "Epoch 76/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.2598 - accuracy: 0.9143 - val_loss: 0.6453 - val_accuracy: 0.7143\n",
      "Epoch 77/200\n",
      "15/15 [==============================] - 1s 88ms/step - loss: 0.3092 - accuracy: 0.8879 - val_loss: 0.6297 - val_accuracy: 0.7347\n",
      "Epoch 78/200\n",
      "15/15 [==============================] - 1s 87ms/step - loss: 0.2070 - accuracy: 0.9275 - val_loss: 0.9847 - val_accuracy: 0.6020\n",
      "Epoch 79/200\n",
      "15/15 [==============================] - 1s 89ms/step - loss: 0.2008 - accuracy: 0.9275 - val_loss: 0.7367 - val_accuracy: 0.7449\n",
      "Epoch 80/200\n",
      "15/15 [==============================] - 1s 94ms/step - loss: 0.1714 - accuracy: 0.9341 - val_loss: 0.8053 - val_accuracy: 0.6939\n",
      "Epoch 81/200\n",
      "15/15 [==============================] - 1s 98ms/step - loss: 0.2009 - accuracy: 0.9143 - val_loss: 0.7172 - val_accuracy: 0.7449\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = classification_model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 0s - loss: 0.5359 - accuracy: 0.7041 - 348ms/epoch - 87ms/step\n",
      "Val Accuracy: 70.41%\n",
      "Val Loss: 0.5359\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the val set\n",
    "val_loss, val_accuracy = classification_model.evaluate(X_val, y_val, verbose=2)\n",
    "print(f\"Val Accuracy: {val_accuracy * 100:.2f}%\")\n",
    "print(f\"Val Loss: {val_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - 1s - loss: 0.4940 - accuracy: 0.7629 - 672ms/epoch - 168ms/step\n",
      "Test Accuracy: 76.29%\n",
      "Test Loss: 0.4940\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the test set\n",
    "test_loss, test_accuracy = classification_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "print(f\"Test Loss: {test_loss:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_json = classification_model.to_json()\n",
    "with open(\"../models_features/CNN_ODOC.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Saving the model and weights\n",
    "classification_model.save_weights('../models_features/CNN_ODOC.weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
