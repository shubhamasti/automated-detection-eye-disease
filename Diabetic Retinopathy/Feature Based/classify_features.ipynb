{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.utils import shuffle, resample\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.utils import load_img, img_to_array, to_categorical\n",
    "from keras.models import model_from_json, Model\n",
    "from keras.optimizers import SGD, RMSprop, Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv('path/to/DDR/DR_grading/labels.csv')\n",
    "df = df[df['label'] != 5]\n",
    "\n",
    "# Define constants\n",
    "IMAGE_SIZE = (256, 256)  # Example size, adjust to your models\n",
    "NUM_CLASSES = 5  # Grading levels 0-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EX\n",
    "with open('../models_segmentation/EX.json', 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "model_hard_exudates = model_from_json(model_json)\n",
    "model_hard_exudates.load_weights('../models_segmentation/EX.weights.h5')\n",
    "model_hard_exudates.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# SE\n",
    "with open('../models_segmentation/SE.json', 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "model_soft_exudates = model_from_json(model_json)\n",
    "model_soft_exudates.load_weights('../models_segmentation/SE.weights.h5')\n",
    "model_soft_exudates.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# HE\n",
    "with open('../models_segmentation/HE.json', 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "model_haemorrhages = model_from_json(model_json)\n",
    "model_haemorrhages.load_weights('../models_segmentation/HE.weights.h5')\n",
    "model_haemorrhages.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# MA\n",
    "with open('../models_segmentation/MA.json', 'r') as json_file:\n",
    "    model_json = json_file.read()\n",
    "model_microaneurysms = model_from_json(model_json)\n",
    "model_microaneurysms.load_weights('../models_segmentation/MA.weights.h5')\n",
    "model_microaneurysms.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhance_img(img):\n",
    "    # Step 1: Apply median filter with a 3x3 kernel\n",
    "    img = cv2.medianBlur(img.astype(np.uint8), ksize=3)\n",
    "\n",
    "    # Step 2: Convert to LAB color space\n",
    "    lab_img = cv2.cvtColor(img, cv2.COLOR_RGB2LAB)\n",
    "    l, a, b = cv2.split(lab_img)\n",
    "\n",
    "    # Step 3: Apply CLAHE on the Luminosity (L) channel with 8x8 tile grid\n",
    "    clahe = cv2.createCLAHE(clipLimit=6.0, tileGridSize=(8, 8))\n",
    "    l = clahe.apply(l)\n",
    "\n",
    "    # Step 4: Merge CLAHE enhanced L with original A and B channels\n",
    "    lab_img = cv2.merge((l, a, b))\n",
    "\n",
    "    # Step 5: Convert back to RGB color space\n",
    "    enhanced_img = cv2.cvtColor(lab_img, cv2.COLOR_LAB2RGB)\n",
    "    \n",
    "    return enhanced_img\n",
    "\n",
    "def get_mask(path, target_size):     \n",
    "    image = cv2.imread(path)\n",
    "    image = cv2.resize(image, target_size)\n",
    "    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Convert image to HSV (Hue, Saturation, Value) color space\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Define the red color range for masking\n",
    "    lower_red = np.array([0, 100, 50])\n",
    "    upper_red = np.array([12, 250, 250])\n",
    "    mask1 = cv2.inRange(hsv_image, lower_red, upper_red)\n",
    "\n",
    "    # lower_red2 = np.array([170, 120, 70])\n",
    "    lower_red2 = np.array([10, 60, 70])\n",
    "    upper_red2 = np.array([180, 255, 255])\n",
    "    mask2 = cv2.inRange(hsv_image, lower_red2, upper_red2)\n",
    "    mask2 = cv2.bitwise_not(mask2)\n",
    "\n",
    "    # Combine masks for red\n",
    "    red_mask = mask1 + mask2\n",
    "    \n",
    "    # overlay the mask on the original image\n",
    "    red_mask_3ch = cv2.cvtColor(red_mask, cv2.COLOR_GRAY2BGR)\n",
    "    mask = cv2.addWeighted(image_rgb, 0.7, red_mask_3ch, 0.3, 0)\n",
    "    \n",
    "    return mask\n",
    "\n",
    "# Define function to preprocess images\n",
    "def preprocess_image_EX(image_path):\n",
    "    img = load_img(image_path, target_size=IMAGE_SIZE)\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def preprocess_image_SE(image_path):\n",
    "    img = load_img(image_path, target_size=IMAGE_SIZE)\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def preprocess_image_HE(image_path):\n",
    "    img = load_img(image_path, target_size=IMAGE_SIZE)\n",
    "    img = img_to_array(img)\n",
    "    img = enhance_img(img)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def preprocess_image_MA(image_path):\n",
    "    img = img = get_mask(image_path, target_size=IMAGE_SIZE)\n",
    "    img = img_to_array(img)\n",
    "    img = img / 255.0\n",
    "    return img\n",
    "\n",
    "def generate_feature_maps(image_path, size=(128, 128)):\n",
    "    # Apply the specific preprocessing method for each model\n",
    "    img_hard = preprocess_image_EX(image_path)\n",
    "    img_soft = preprocess_image_SE(image_path)\n",
    "    img_haem = preprocess_image_HE(image_path)\n",
    "    img_micro = preprocess_image_MA(image_path)\n",
    "\n",
    "    # Add batch dimensions for predictions\n",
    "    img_hard = np.expand_dims(img_hard, axis=0)\n",
    "    img_soft = np.expand_dims(img_soft, axis=0)\n",
    "    img_haem = np.expand_dims(img_haem, axis=0)\n",
    "    img_micro = np.expand_dims(img_micro, axis=0)\n",
    "\n",
    "    # Generate masks\n",
    "    \n",
    "    mask1 = model_hard_exudates.predict(img_hard, verbose=False)  # Predict mask\n",
    "    mask1 = (mask1 > 0.1).astype(int)  # Convert to binary\n",
    "    \n",
    "    mask2 = model_soft_exudates.predict(img_soft, verbose=False)  # Predict mask\n",
    "    mask2 = (mask2 > 0.1).astype(int)  # Convert to binary\n",
    "    \n",
    "    mask3 = model_haemorrhages.predict(img_haem, verbose=False)  # Predict mask\n",
    "    mask3 = (mask3 > 0.1).astype(int)  # Convert to binary\n",
    "    \n",
    "    mask4 = model_microaneurysms.predict(img_micro, verbose=False)  # Predict mask\n",
    "    mask4 = (mask4 > 0.1).astype(int)  # Convert to binary\n",
    "    \n",
    "    # make hard exudates mask red channel, soft exudates mask green channel, haemorrhages mask blue channel, microaneurysms mask alpha channel\n",
    "    mask1 = tf.image.resize(mask1, size)\n",
    "    mask2 = tf.image.resize(mask2, size)\n",
    "    mask3 = tf.image.resize(mask3, size)\n",
    "    mask4 = tf.image.resize(mask4, size)\n",
    "\n",
    "    # Combine masks into a single feature map\n",
    "    combined = np.concatenate([mask1, mask2, mask3, mask4])  # Shape: (H, W, 4)\n",
    "    combined = np.transpose(combined, (1, 2, 0, 3))\n",
    "    combined = np.squeeze(combined)\n",
    "    \n",
    "    return combined\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target sample sizes for each label\n",
    "target_sizes = {\n",
    "    0: 500,\n",
    "    1: 500,\n",
    "    2: 500,\n",
    "    3: 500,\n",
    "    4: 500\n",
    "}\n",
    "\n",
    "# Initialize a list to hold the sliced DataFrames\n",
    "sliced_dfs = []\n",
    "\n",
    "# Slice the DataFrame for each label\n",
    "for label, size in target_sizes.items():\n",
    "    class_df = df[df['label'] == label]\n",
    "    if len(class_df) >= size:\n",
    "        # Undersample if the class size is greater than or equal to the target size\n",
    "        sliced_df = class_df.sample(size, random_state=42)\n",
    "    else:\n",
    "        # Oversample if the class size is smaller than the target size\n",
    "        sliced_df = resample(class_df, replace=True, n_samples=size, random_state=42)\n",
    "    sliced_dfs.append(sliced_df)\n",
    "\n",
    "# Combine all sliced DataFrames\n",
    "final_df = pd.concat(sliced_dfs)\n",
    "\n",
    "# Shuffle the final dataset\n",
    "final_df = shuffle(final_df, random_state=42)\n",
    "\n",
    "final_df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare dataset\n",
    "dataset_path = 'path/to/DDR/DR_grading/all'\n",
    "\n",
    "X_features = []\n",
    "y_labels = []\n",
    "\n",
    "for index, row in tqdm(final_df.iterrows(), total=len(final_df), desc=\"Processing rows\"):\n",
    "    image_path = row['image']\n",
    "    label = row['label']\n",
    "    \n",
    "    image_path = os.path.join(dataset_path, image_path)\n",
    "    \n",
    "    combined_features = generate_feature_maps(image_path, size=(256, 256))\n",
    "    X_features.append(combined_features)\n",
    "    y_labels.append(label)\n",
    "\n",
    "X = np.array(X_features)\n",
    "y = np.array(y_labels)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_present = (y > 0).astype(int)  # Binary: 0 (no disease), 1 (disease present)\n",
    "y_grades = np.where(y_present == 1, y, 0)  # Multiclass: 1-4 if disease present, 0 otherwise\n",
    "y_grades = to_categorical(y_grades, num_classes=5)\n",
    "\n",
    "X_train, X_test, y_present_train, y_present_test, y_grades_train, y_grades_test = train_test_split(\n",
    "    X, y_present, y_grades, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_val, y_present_train, y_present_val, y_grades_train, y_grades_val = train_test_split(\n",
    "    X_train, y_present_train, y_grades_train, test_size=0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_present_train.shape, y_grades_train.shape, y_present_val.shape, y_grades_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input layer\n",
    "input_layer = tf.keras.layers.Input(shape=(256, 256, 4))\n",
    "\n",
    "# Shared convolutional layers\n",
    "conv1 = tf.keras.layers.Conv2D(32, (3, 3), activation='relu')(input_layer)\n",
    "pool1 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "conv2 = tf.keras.layers.Conv2D(64, (3, 3), activation='relu')(pool1)\n",
    "pool2 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "conv3 = tf.keras.layers.Conv2D(128, (3, 3), activation='relu')(pool2)\n",
    "pool3 = tf.keras.layers.MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "conv4 = tf.keras.layers.Conv2D(256, (3, 3), activation='relu')(pool3)\n",
    "pool4 = tf.keras.layers.GlobalAveragePooling2D()(conv4)\n",
    "# Fully connected layers\n",
    "fc0 = tf.keras.layers.Dense(2048, activation='relu')(pool4)\n",
    "drop0 = tf.keras.layers.Dropout(0.3)(fc0)\n",
    "fc1 = tf.keras.layers.Dense(1024, activation='relu')(fc0)\n",
    "drop1 = tf.keras.layers.Dropout(0.3)(fc1)\n",
    "fc2 = tf.keras.layers.Dense(512, activation='relu')(drop1)\n",
    "drop2 = tf.keras.layers.Dropout(0.3)(fc2)\n",
    "fc3 = tf.keras.layers.Dense(256, activation='relu')(drop2)\n",
    "drop3 = tf.keras.layers.Dropout(0.3)(fc3)\n",
    "fc4 = tf.keras.layers.Dense(128, activation='relu')(drop3)\n",
    "drop4 = tf.keras.layers.Dropout(0.3)(fc4)\n",
    "fc5 = tf.keras.layers.Dense(64, activation='relu')(drop4)\n",
    "drop5 = tf.keras.layers.Dropout(0.3)(fc5)\n",
    "fc6 = tf.keras.layers.Dense(32, activation='relu')(drop5)\n",
    "drop6 = tf.keras.layers.Dropout(0.3)(fc6)\n",
    "fc7 = tf.keras.layers.Dense(16, activation='relu')(drop6)\n",
    "drop7 = tf.keras.layers.Dropout(0.3)(fc7)\n",
    "\n",
    "# Output 1: Presence of disease (binary classification)\n",
    "present_output = tf.keras.layers.Dense(1, activation='sigmoid', name='present_output')(drop0)\n",
    "\n",
    "# Output 2: Disease grading (multi-class classification, conditioned on disease presence)\n",
    "grade_output = tf.keras.layers.Dense(5, activation='softmax', name='grading_output')(drop7)\n",
    "\n",
    "classification_model = tf.keras.Model(inputs=input_layer, outputs=[present_output, grade_output])\n",
    "\n",
    "# Compile the model\n",
    "losses = {\n",
    "    'present_output': 'binary_crossentropy',\n",
    "    'grading_output': 'categorical_crossentropy'\n",
    "}\n",
    "loss_weights = {\n",
    "    'present_output': 1.0,  # Weight for disease presence\n",
    "    'grading_output': 1.0  # Weight for disease grading\n",
    "}\n",
    "\n",
    "# adam optimizer is used with a learning rate of 0.001\n",
    "classification_model.compile(optimizer=Adam(learning_rate=0.001), loss=losses, loss_weights=loss_weights, metrics=['accuracy'])\n",
    "\n",
    "classification_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',  # Metric to monitor\n",
    "    patience=10,          # Number of epochs with no improvement before stopping\n",
    "    restore_best_weights=True  # Restore weights from the epoch with the best validation loss\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model.fit(X_train, {'present_output': y_present_train, 'grading_output': y_grades_train}, \n",
    "                         batch_size=32, steps_per_epoch=int(len(X_train) / 32),\n",
    "                         epochs=100, callbacks=[early_stopping],\n",
    "                         validation_data=(X_val, {'present_output': y_present_val, 'grading_output': y_grades_val}),\n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "scores = classification_model.evaluate(X_val, {'present_output': y_present_val, 'grading_output': y_grades_val})\n",
    "print(\"Val Accuracy (Presence): %.2f%%\" % (scores[3] * 100))  # Accuracy for present_output\n",
    "print(\"Val Loss (Presence): %.2f\" % scores[1])\n",
    "print(\"Val Accuracy (Grading): %.2f%%\" % (scores[4] * 100))  # Accuracy for grading_output\n",
    "print(\"Val Loss (Grading): %.2f\" % scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "scores = classification_model.evaluate(X_test, {'present_output': y_present_test, 'grading_output': y_grades_test})\n",
    "print(\"Test Accuracy (Presence): %.2f%%\" % (scores[3] * 100))  # Accuracy for present_output\n",
    "print(\"Test Loss (Presence): %.2f\" % scores[1])\n",
    "print(\"Test Accuracy (Grading): %.2f%%\" % (scores[4] * 100))  # Accuracy for grading_output\n",
    "print(\"Test Loss (Grading): %.2f\" % scores[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model_json = classification_model.to_json()\n",
    "with open(\"../models_features/CNN_all_features.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Saving the model and weights\n",
    "classification_model.save_weights('../models_features/CNN_all_features.weights.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
